<!DOCTYPE HTML>

<html>

<head>
	<title>Pre-Thesis F'18 | Parvez Kose</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<link rel="stylesheet" href="assets/css/styles.css" />
</head>

<body>

	<!-- Wrapper -->
	<div id="wrapper" class="divided">

		<!-- One -->
		<section class="banner style1 orient-left content-align-left image-position-right fullscreen onload-image-fade-in onload-content-fade-right">
			<div class="content">
				<h1>Parvez Kose</h1>
				<p class="major">Pre-Thesis site</p>
				<ul class="actions vertical">
					<li>
						<a href="#assignment-8" class="button big wide smooth-scroll-middle">Get Started</a>
					</li>
				</ul>
			</div>
			<div class="image">
				<!--<img src="images/Deep-learning_v2.jpg" alt="" />-->
			</div>
		</section>

		<section id="assignment-8" class="spotlight wrapper style1 align-left">
			<div class="inner">

				<h2 class="center">Assignment No.8</h2>

				<div class="index align-left">
					<section>
						<div class="tire">
							<div class="dark-blue">
								<h3>Prototype</h3>

								<div>
									<h4>Prototype: Image Classification on Web</h4>
									<a target="_blank" href="http://parvezk.github.io/pre-thesis/prototype-1/index.html">http://parvezk.github.io/pre-thesis/prototype-1/index.html</a>
									<br /><br />
									<div>
										<p>The concept for the prototype is to build a client side artificial neural network, which can help deploy and run deep learning models on the web. We developed an image classifier that recognizes objects in the images and runs entirely in the browser, using Javascript and high-level layers API.
											</p>
											<p> We use TensorFlow’s Javascript library: TensorFlow.js, a WebGL-accelerated, browser-based JavaScript library for training and deploying machine learning models on web It allows training neural networks on the browser or run pre-trained models in inference mode.
											</p>
											
											<p>This demo uses the pre-trained MobileNet_25_224 model from Keras <a href="https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_2_5_224_tf.h5">here</a>.. Keras is an open source neural network library written in Python. It is designed to enable fast experimentation with deep neural networks.</p>
										
										<p>It is not trained to recognize human faces. For best performance, upload images of objects like piano, coffee mugs, bottles, etc.</p>
									</div>
								</div>


							</div>


						</div>
					</section>

				</div>
			</div>
		</section>

		<section id="assignment-7" class="wrapper style1 align-left">
			<div class="inner">

				<h2 class="center">Assignment No.7</h2>

				<div class="index align-left">
					<section>
						<div class="tire">
							<div class="dark-blue">
								<h3>Outline for the Abstract Paper</h3>
								<ul>
									<li>Interpretable Machine Learning: Explore and interpret machine learning models</li>
									<li>New interactive model analysis techniques and systems.</li>
									<li>Method to interpret and understand deep neural networks</li>
									<li>What better tools for visualizing and interpreting neural nets</li>
									<li>Understand how and why a model work, how classifier works?</li>
									<li>Interactive Visualization to understand, diagnose, and refine a neural network model</li>
									<li>Combine recent advances in computer vision and natural language processing</li>
								</ul>

							</div>


						</div>
					</section>

				</div>
			</div>
		</section>

		<section id="assignment-6" class="wrapper style1 align-left">
			<div class="inner">

				<h2 class="center">Assignment No.6</h2>

				<div class="index align-left">
					<section>
						<div class="tire">
							<div class="dark-blue">
								<h3>Research Overview</h3>
								<p>I am profoundly excited by the idea of designing and interpreting the artificial neural networks. With the
									growing success of neural networks and deep learning, there is an increasing need to be able to interpret them
									and understand their design and inner workings of them.</p>

								<p>What better tools would help interpret the deep neural networks and other machine learning algorithms.</p>

								<p>Deep learning, has proved very powerful at solving problems in recent years, and it has been widely deployed
									for tasks like image captioning, voice recognition, and language translation. There is now hope that the same
									techniques will be able to diagnose deadly diseases, make trading decisions, and do countless other things to
									transform whole industries.</p>

								<p>Without a clear understanding of how and why a model works, the development of these models typically relies
									on a time-consuming trial-and-error process. As a result, academic researchers and industrial practitioners
									are facing challenges that demand more transparent and explainable systems for better understanding and
									analyzing machine learning models, especially their inner working mechanisms.</p>

								<p>I strongly believe it is a problem that is already relevant, and it’s going to be much more relevant in the
									future. Whether it’s an investment decision, a medical decision, or maybe a military decision, we don’t want
									to just rely on a ‘black box’ method. It’s time to act on making their decisions understandable, before the
									technology is even more pervasive.</p>

								<p>I am interested in the idea of an interactive model that could help understand, diagnose, and refine a
									machine learning model with the help of interactive visualization.</p>

								<p>The idea of explaining how AI technique work using an interactive model and aided with rich visualizations
									will not only be interesting and useful, but also discerning from the current tools and methods that involves
									significant mathematical notations and statistical knowledge.</p>

								<p>I am most excited by the idea of a rich design space for interacting with the neural network. This would
									further help us explore their untapped potentials. It promises to be a powerful tool in enabling meaningful
									human oversight and in building a fair, safe, and aligned AI systems.</p>
							</div>


						</div>
					</section>

				</div>
			</div>
		</section>

		<section id="assignment-5" class="wrapper style1 align-left">
			<div class="inner">

				<h2 class="center">Assignment No.5</h2>

				<div class="index align-left">
					<section>
						<div class="tire">
							<div class="dark-blue dialogic">
								<h3>Dialogic Journal</h3>
							</div>
							<div class="green">
								<img width="90%" src="images/W5/dialog-1.jpg" alt="">
							</div>
							<div class="green">
								<img width="90%" src="images/W5/dialog-2.jpg" alt="">
							</div>
						</div>
					</section>
					<section style="display: block;">
						<h4>Dialogic Journal on Google sheets</h4>
						<br />
						<img width="70%" src="images/W5/dialogic-google-sheet.jpg" alt="">
						<br />
						<p>
							<a href="https://docs.google.com/spreadsheets/d/19XjWZKtXEpVd7UHFGWpzy3GUiBLJE3Bbg0ePzllngMg/edit?usp=sharing">Link
								to Dialogic Journal on Google Drive</a>
						</p>
						<br />
					</section>
				</div>
			</div>
		</section>
		<!-- article 1-->
		<section class=" wrapper style1 align-left">

			<div class="inner">
				<h3>Summary of five articles</h3>

				<div class="index align-left">
					<section>

						<div class="tire">
							<div class="dark-blue ">
								<h4 class="pre">Article 1:</h4>
								<h4 class="center"> The Building Blocks of Interpretability</h4>

								<blockquote class="citation">
									<cite>Olah, Chris, et al. </cite><q>The Building Blocks of Interpretability.</q>, Distill 2018,
									distill.pub/2018/building-blocks/.
								</blockquote>
								<pre class="keywords"><strong>Keywords: </strong> Intelligibility; explanations; explainable artificial intelligence interpretable machine learning</pre>
							</div>
							<div class="dark-blue ">
								<p>With the growing success of neural networks and deep learning, there is an increasing need to be able to
									explain how neural networks make their decisions — there is a growing need to explain how they make their
									decisions, including building confidence about how they behave in the real-world, detecting model bias, and
									for scientific curiosity.</p>
							</div>
							<div class="green">
								<img width="100%" src="images/W5/a1-1.jpg" alt="">
							</div>

							<div class="green" style="text-align:right">
								<img width="40%" src="images/W5/a1-3.jpg" alt="">
							</div>
							<div class="dark-blue">
								<p>This paper discusses how we can develop tools to better interpret neural network models. This article
									categorizes those techniques into (1) feature visualization (2) feature attribution (3) feature grouping and
									shows that these can be integrated into an interactive interface as layers to let users get a sense of the
									internals of an image network. The article first motivates the reason to understand the network through
									canonical examples and visualization of concepts such as activation of neurons.</p>

								<p>The next section talks about performing feature visualization at every spatial location across all channels.
									The visualizations are visually appealing, and really give a sense of how the model comes to its decision. I’m
									very excited to see such visualizations applied to other image datasets. Then it discuss how different
									concepts at different layers influence and are influenced by concepts in other layers. This is the first
									visualization of its kind that I’ve seen and seems like it could be extremely valuable in helping determining
									many details..</p>

							</div>
							<div class="green">
								<img width="100%" src="images/W5/a1-2.jpg" alt="">
							</div>

							<div class="dark-blue ">
								<p>Beyond interfaces for analyzing model behavior, we can consider interfaces for taking action on neural
									networks, where the training models can learn from human feedback. Human feedback on the model’s
									decision-making process, facilitated by interpretability interfaces, could be a powerful solution to these
									problems. It might allow us to train models not just to make the right decisions, but to make them for the
									right reasons.</p>
								<p>This suggests that we need more fundamental research, at the intersection of machine learning and
									human-computer interaction, to resolve some of these interepretability issues. Given these model behaviors are
									complex, author remarks that an important direction for future interpretability research will be developing
									techniques that achieve broader coverage of model behavior. Some other possibilities are interfaces for
									comparing multiple models. For instance, we might want to see how a model evolves during training.</p>
							</div>
						</div>
						<header></header>
					</section>
				</div>
			</div>
		</section>
		<!-- article 2-->
		<section class=" wrapper style1 align-left">

			<div class="inner">
				<div class="index align-left">
					<section>

						<div class="tire">
							<div class="dark-blue ">
								<h4 class="pre">Article 2:</h4>
								<h4 class="center">Embedding Projector: Interactive Visualization and Interpretation of Embeddings</h4>

								<blockquote class="citation">
									<cite>Smilkov, Daniel, et al.</cite><q>
										Embedding Projector: Interactive Visualization and Interpretation of Embeddings.</q>, ARXIV, 11/2016,
									arXiv:1611.05469 [stat.ML]
								</blockquote>
								<pre class="keywords"><strong>Keywords: </strong> Statistics - Machine Learning, Computer Science - Human-Computer Interaction</pre>
							</div>
							<div class="dark-blue ">
								<p>An embedding is a map from the data to points in Euclidean space. Embeddings are everywhere in machine
									learning, appearing in recommender systems, Natural Language Processing, and many other applications.
									Researchers and developers often need to explore the properties of a specific embedding, and one way to
									analyze embeddings is to visualize them.</p>
							</div>
							<div class="green">
								<img width="100%" src="images/W5/ar2-1.jpg" alt="">
							</div>
							<div class="dark-blue ">
								<p>The paper presents Embedding Projector, a new visualization tool that helps users interpret machine learning
									models that rely on embeddings. Unlike other high-dimensional visualization systems, it is customized for the
									kinds of tasks faced by machine learning developers and researchers: exploring local neighborhoods for
									individual points, analyzing global geometry, and investigating semantically meaningful vectors in embedding
									space.</p>
							</div>
							<div class="green">
								<img width="100%" src="images/W5/ar2-2.jpg" alt="">
							</div>
							<div class="dark-blue ">
								<p>It can be seen that there are a number of directions for future work on visualization. For example, when
									developing multiple versions of a model, or inspecting how a model changes over time, it could be useful to
									visually compare two embeddings. The paper highlights that a second direction for future research could be
									make it easier for users to discover meaningful directions in the data. While the current interface makes it
									easy to explore various hypotheses, there may be ways for the computer to generate and test hypotheses
									automatically.</p>

							</div>
						</div>
						<header></header>
					</section>
				</div>
			</div>
		</section>
		<!-- article 3-->
		<section class=" wrapper style1 align-left">
			<div class="inner">

				<div class="index align-left">
					<section>

						<div class="tire">
							<div class="dark-blue ">
								<h4 class="pre">Article 3:</h4>
								<h4 class="center">Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow</h4>

								<blockquote class="citation">
									<cite>Wongsuphasawat, K. (. 1. )., et al. </cite><q>Visualizing Dataflow Graphs of Deep Learning Models in
										TensorFlow.</q>, IEEE Transactions on Visualization and Computer Graphics, vol. 24
									doi:10.1109/TVCG.2017.2744878.
								</blockquote>
								<pre class="keywords"><strong>Keywords: </strong> Clustered Graph; Dataflow Graph; Graph Visualization; Index Terms-Neural Network</pre>
							</div>
							<div class="dark-blue ">
								<p>Deep learning models are becoming increasingly important in many applications. Understanding and debugging
									these models, however, remains a major issue. This paper describes a design study of a visualization tool that
									tackles one aspect of this challenge: interactive exploration of the dataflow architecture behind machine
									learning models.</p>

								<p>This tool helps users understand complex machine learning architectures by visualizing their underlying
									dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout
									techniques to produce a legible interactive diagram.</p>
							</div>
							<div class="green">
								<img width="60%" src="images/W5/ar3-1.jpg" alt="">
							</div>
							<div class="green">
								<img width="60%" src="images/W5/ar3-2.jpg" alt="">
							</div>

							<div class="dark-blue ">
								<p>The design process emphasizes understanding of both users and data: It describe a task analysis for
									developers of deep learning models, and outline the challenges presented by model structures. The author then
									present a series of graph transformation to address these challenges, and demonstrate usage scenarios. They
									also discuss user re- actions.</p>
								<p>Users (researchers, engineers and designers) find the visualizer useful for understanding, debugging, and
									sharing the structures of their models. This shows that users derived significant value from the
									visualizations, which is a welcome sign for visualization creators</p>
								<p>Author concludes by saying developer reactions suggest a heartfelt desire for better ways to understand
									machine learning. This is an area in which data is central, but the tools have not matured, and users often
									feel they operate in the dark. Visualization may have an important role to play.</p>
							</div>
						</div>
						<header></header>
					</section>
				</div>
			</div>
		</section>
		<!-- article 4-->
		<section class=" wrapper style1 align-left">
			<div class="inner">

				<div class="index align-left">
					<section>

						<div class="tire">
							<div class="dark-blue ">
								<h4 class="pre">Article 4:</h4>
								<h4 class="center">Feature Visualization</h4>

								<blockquote class="citation">
									<cite>Olah, C.,</cite><q>Feature Visualization  [link]</q>, Distill, 2017 DOI: 10.23915/distill.00007
								</blockquote>
								<pre class="keywords">Deep Learning, Neural Network, GoogLeNet Visualizations, Interactive Visualizations</pre>
							</div>

							<div class="dark-blue ">
								<p>Neural networks are algorithms inspired by the biological brain. Deep learning is a set of techniques for
									learning in neural networks. They have made a huge impact on a wide variety of applications recently. They
									provide some of best solutions to many problem in image recognition, voice recognition and autonomous driving.</p>
							</div>
							<div class="green">
								<img width="80%" src="images/W5/a4-1.jpg" alt="">
							</div>

							<div class="dark-blue ">
								<p>While deep neural networks learn efficient and powerful representations, they are often considered a
									‘black-box’. With their growing influence in our lives, there is a critical need to better understand their
									decisions and to gain insight into how these models operate. This paper attempts to interpret a neural network
									model for an image classification task.</p>
								<p>Feature visualization is one of the important techniques to understand what neural networks have learned
									from image dataset. This paper focuses on optimization methods and discusses major issues and explore common
									approaches to solving them.</p>
								<p>The author presents a comprehensive overview on feature visualization, mainly focusing on optimization
									method. It starts with explaining why use optimization method to visualize feature in neural networks compared
									to finding examples from the dataset. Then discuss how to achieve diversity with optimization. Then further
									discuss the interaction between neurons, which can explore the combinations of neurons working together to
									represent images in neural networks. Finally, discuss how to improve the optimization process better by adding
									different regularizations methods.</p>

								<p>The author concludes by saying feature visualization stands out as one of the most promising and developed
									research directions. By itself, feature visualization might never give a completely satisfactory
									understanding. But as one of the fundamental building blocks when, combined with additional tools, will
									empower humans to understand these systems.</p>
							</div>
						</div>
						<header></header>
					</section>
				</div>
			</div>
		</section>
		<!-- article 5-->
		<section class=" wrapper style1 align-left">
			<div class="inner">
				<div class="index align-left">
					<section>
						<div class="tire">
							<div class="dark-blue ">
								<h4 class="pre">Article 5:</h4>
								<h4 class="center">Show and Tell Image Captioning Challenge</h4>

								<blockquote class="citation">
									<cite>Vinyals, O., et al.</cite><q>Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning
										Challenge.</q>, IEEE Transactions on Pattern Analysis and Machine Intelligence, no. 4, 2017.
								</blockquote>
								<pre class="keywords">Image captioning, recurrent neural network, sequence-to-sequence, language model.</pre>
							</div>

							<div class="dark-blue ">
								<p>This paper presents a machine learning model, which is trained to describe the content of an image. Until
									recently, it was a fundamental problem in the artificial intelligence area that connects two emerging fields:
									computer vision and natural language processing.</p>
								<img width="80%" src="images/W5/a5-1.jpg" alt="">
								<p>The work is inspired by the recent advances in machine translation such as Google translate application. For
									many years, machine translation was achieved by a series of separate tasks, but recent work has shown that
									translation can be done in a much simpler way and still reach greater performance.</p>
							</div>

							<div class="dark-blue ">
								<p>The paper proposes a a neural and probabilistic framework to generate descriptions from images. These models
									make use of an architecture called called Recurrent Neural Network (RNN) that combines recent advances in
									computer vision and machine translation and that can be used to generate natural sentences describing an
									image. The model is trained to maximize the likelihood of the target description given the training image. </p>
							</div>
							<div class="green">
								<img width="90%" src="images/W5/a5-2.jpg" alt="">
							</div>
							<div class="dark-blue ">
								<p>They present an end-to-end system for the problem. It is a neural net which is fully trainable using
									stochastic gradient descent. then, their model combines sub-networks for vision and language models. They can
									be pre-trained on larger corpora and thus can take advantage of additional data.</p>
								<p>This paper was the result of a competition for an image captioning challenge, organized by Microsoft in
									2015, where the team contested and won and placed equal first with Microsoft Research. The authors discusses
									the resulting performance in the competition and experiments on several datasets.</p>
							</div>
						</div>
						<header></header>
					</section>
				</div>
			</div>
		</section>

		<section id="assignment-4" class=" wrapper style1 align-left">
			<div class="inner">

				<h3>Assignment Week 4</h3>

				<div class="index align-left">
					<section>

						<div class="content">

							<p><strong>Step 1 - Big Problem</strong></p>
							<p>With the growing complexity of artificial neural networks, the critical need for understanding their
								inner-workings has
								increased. It is being used to guide all sorts of key decisions in medicine, finance, manufacturing and beyond,
								including determining who gets healthcare, who’s approved for a loan and who gets hired for a job.</p>
						</div>
						<header>

						</header>

					</section>
				</div>
			</div>
		</section>

		<section id="assignment-4" class=" wrapper style1 align-left">
			<div class="inner">


				<div class="index align-left">

					<section>


						<div class="content">
							<h3></h3>
							<p><strong>Step 1A - Big Problem with Data</strong></p>
							<ul>
								<li>Machine Learning is a subset of artificial intelligence. It allows the machines to learn and make
									predictions based on its experience (data). </li>
								<li>Machine learning has been successfully applied to a wide variety of fields ranging from information
									retrieval, data mining, and speech recognition, to computer graphics, visualization, and human–computer
									interaction. However, most users often treat a machine learning model as a black box because of its
									incomprehensible functions and unclear working mechanism.</li>
								<li>The AI technology, known as deep learning, has proved very powerful at solving problems in recent years,
									and it has been widely deployed for tasks like image captioning, voice recognition, and language translation.
									There is now hope that the same techniques will be able to diagnose deadly diseases, make trading decisions,
									and do countless other things to transform whole industries.</li>
								<li>Without a clear understanding of how and why a model works, the development of these models typically
									relies on a time-consuming trial-and-error process. As a result, academic researchers and industrial
									practitioners are facing challenges that demand more transparent and explainable systems for better
									understanding and analyzing machine learning models, especially their inner working mechanisms.</li>
								<li>“It is a problem that is already relevant, and it’s going to be much more relevant in the future,” says
									Tommi Jaakkola, a professor at MIT who works on applications of machine learning. “Whether it’s an investment
									decision, a medical decision, or maybe a military decision, you don’t want to just rely on a ‘black box’
									method.”. It’s time to act on making their decisions understandable, before the technology is even more
									pervasive.</li>

							</ul>
						</div>

					</section>

					<section>

						<div class="content">
							<h3></h3>
							<p><strong>Step 2A - Stakeholder map</strong></p>
							<div><img width="50%" src="images/W4/stakeholder_map.png" alt=""></div>
						</div>

					</section>

					<section>
						<header>

						</header>
						<div class="content">

							<p><strong>Step 2B - Stakeholder list</strong></p>
							<div>
								<ul>
									<li>Data Scientists</li>
									<li>AI Researchers</li>
									<li>Machine Learning Engineers</li>
									<li>PhD & Post-doctoral students</li>
									<li>Research & Development centers</li>
									<li>Stock Traders</li>
									<li>Economic Analysts</li>
									<li>University Lab & centres</li>
								</ul>
							</div>
						</div>

					</section>

					<section>
						<header>

						</header>
						<div class="content">

							<p><strong>Step 3A Personas</strong></p>

							<div>
								<h4>Data Scientists</h4>
								<p>Data scientists and engineers, who are facing challenges that demand more transparent and explainable
									systems for better understanding and analyzing machine learning models in their projects, especially their
									inner working mechanisms.</p>
								<p>
									An interactive visualization of these models is needed to effectively solve some of the real world challenges.
									An interactive model could help data scientist understand, diagnosing, and refining a machine learning model
									with the help of interactive visualization.
								</p>
							</div>


						</div>
					</section>

					<section>
						<header>

						</header>
						<div class="content">
							<h3></h3>
							<p><strong>Step 3B - User List</strong></p>
							<div>
								<ul>
									<li>Chetan N.G, System Engineers, NVIDIA</li>
									<li>Enrico Bertini, Assistant Professor, Department of Computer Science and Engineerin, NYU Tandon School of
										Engineering</li>
									<li>Xianbo Xi, PhD Student, Tandon School of Engineering</li>
								</ul>
							</div>
						</div>
				</div>
			</div>
		</section>

		<section id="assignment-3" class=" wrapper style1 align-left">
			<div class="inner">
				<h2>Assignment No.3</h2>

				<div class="index align-left">

					<section>
						<div>
							<h3>Step 1: Determining Area & Topic</h3>
							<p><strong>Area: </strong>Machine Learning</p>
							<p><strong>Topic: </strong>Neural Networks</p>
							<h3>Brainstorming, freewriting, and mind mapping</h3>
						</div>

					</section>
				</div>
			</div>
		</section>

		<section class=" wrapper style1 align-left">
			<div class="inner">
				<div class="index align-left">
					<!-- Two -->
					<section>
						<header>
							<p><strong>Brainstorm</strong></p>
						</header>
						<div class="content">
							<img width="45%" style="float:left" src="images/W3/brainstorm-1.jpg" alt="">

							<img width="70%" style="float:left" src="images/W3/brainstorm-2.jpg" alt="">
						</div>
					</section>

					<section>
						<header>
							<p><strong>Freewrite</strong></p>
						</header>
						<div class="content">
							<img width="45%" src="images/W3/freewrite.jpg" alt="">
						</div>
					</section>

					<section>
						<header>
							<p><strong>Mind map</strong></p>
						</header>
						<div class="content">
							<img width="90%" src="images/W3/mind-map-1.JPG" alt="">
						</div>
					</section>

				</div>

		</section>

		<section class=" wrapper style1 align-center">
			<div class="inner">
				<h3 class="left-title">Step 2</h3>
				<div class="index align-left">
					<!-- Two -->
					<section>
						<header>

						</header>
						<div class="content">
							<p><strong>Question - Response - Question</strong></p>

							<section>
								<img width="80%" src="images/W3/QRQ-1.jpg" alt="">
								<br><br>
								<div>
									<p><strong>Augmenting Human Intellect</strong></p>
									<ul>
										<li>How can we use artificial intelligence to augment human intellect?</li>
										<li>Can machine learning help augment human creativity?</li>
										<li>How generative interfaces can be used to explore and visualize machine learning models?</li>
										<li>Will these tools help humans think and create in new ways? </li>
										<li>Can they be used to generate ideas, which are truly original?</li>
										<li>Can such systems be used to develop fundamental new interface primitives?</li>
										<li>How will those new primitives change and expand the way humans think?</li>
									</ul>
								</div>
							</section>

							<section>
								<img width="80%" src="images/W3/QRQ-2.jpg" alt="">
								<br><br>
								<div>
									<p><strong>Explainable AI</strong></p>
									<ul>
										<li>How to explain how AI system works?</li>
										<li>What are the dark secrets of AI systems?</li>
										<li>With their growing complexity and pervasiveness, how do we interpret the inner workings of AI models?</li>
										<li>Can design thinking help solve the issue of explainability?</li>
										<li>Will research at the intersection of HCI and AI help resolve these issues?</li>
										<li>Can visualization techniques help fill such critical need?</li>
										<li>Can visual narratives help bring new insight into the complexity of AI system?</li>
									</ul>
								</div>
							</section>

							<section>
								<img width="80%" src="images/W3/QRQ-3.jpg" alt="">
								<br><br>
								<div>
									<p><strong>Why Neural Network is a black box?</strong></p>
									<ul>
										<li>How neural network learns on its own from the data?</li>
										<li>What does the network see?</li>
										<li>Can we see what the network detects?</li>
										<li>How it assembles various individual pieces as it moves forward?</li>
										<li>Can we detect model bias?</li>
										<li>How does it arrive at the final decision?</li>
										<li>what are the relationships like between different neurons?</li>

									</ul>
								</div>
							</section>


						</div>
					</section>
					<section>
						<header>
							<p><strong>Wheel and Spoke</strong></p>
						</header>
						<div class="content">
							<img width="50%" src="images/W3/wheel-spoke-1.JPG" alt="">
						</div>
					</section>
				</div>
			</div>
		</section>

		<section class=" wrapper style1 align-left">
			<div class="inner">
				<h3 class="">Step 3: List of questions (Factual, Technical, Conceptual)</h3>

				<section>
					<div>
						<h4><strong>Factual</strong></h4>
						<ul>
							<li>How can we enable human potential using emerging technologies?</li>
							<li>How can we augment human intellect with artificial intelligence</li>

							<li>What does the future hold for new field emerging today out of a synthesis of AI and IA?</li>
							<li>What type of research would be useful at the intersection of machine learning and human-computer interaction</li>
						</ul>
					</div>

					<div>
						<h4><strong>Technical</strong></h4>
						<ul>
							<li>How to build visual interface to interpret machine learning algorithms?</li>
							<li>How do we interpret high dimensional data in a visual medium?</li>

						</ul>
					</div>

					<div>
						<h4><strong>Conceptual</strong></h4>
						<ul>
							<li>How do we create a space to interact with neural networks?</li>
							<li>Can we trust deep learning techniques?</li>
							<li>How do we use interpretability methods as powerful tool in enabling meaningful human oversight and in
								building fair, safe, and aligned AI systems</li>
						</ul>
					</div>

					<h4><strong>Accountability Partner</strong></h4>
					<p>Alex Nathanson and Jason Charles are my accountability partners. We will be meeting briefly before pre-thesis
						every Tuesday.</p>
			</div>

		</section>

	</div>
	</section>

	<section class=" wrapper style1 align-center">
		<div class="inner">
			<h2>Assignment No.2</h2>

			<div class="index align-left">
				<!-- Two -->
				<section>
					<header>
						<p><strong>Journal Articles</strong></p>
					</header>
					<div class="content">
						<img width="100%" src="images/W2/journal-articles.png" alt="">
					</div>
				</section>
				<section>
					<header>
						<p><strong>Review Articles</strong></p>
					</header>
					<div class="content">
						<img width="100%" src="images/W2/review-articles.png" alt="">
					</div>
				</section>
			</div>
		</div>
	</section>

	<section class="wrapper style1 align-center">
		<div class="inner">
			<h2>Article Response</h2>
			<p>The five articles I read were:</p>
			<div class="index align-left">
				<!-- Two -->
				<section>
					<header>
						<p><strong></strong></p>
					</header>
					<div class="content">
						<ul>
							<li>Throwing shapes</li>
							<li>Why the Focus on Human Intelligence?</li>
							<li>Mapping’s Intelligent Agents</li>
							<li>Plumbing the Depths of Neural Nets </li>
							<li> Interactive Visualization and Interpretation of Embeddings</li>
						</ul>
					</div>
				</section>

			</div>
		</div>
	</section>

	<section class="wrapper style1 align-center">
		<div class="inner">
			<h2>Responses</h2>
			<p></p>
			<div class="index align-left">

				<section>
					<header>
						<p><strong>Visual Experiments</strong></p>
					</header>
					<div class="content visual-exe">

						<div>
							<h4>Branches of Aritifical Intelligence</h4>
							<img width="100%" src="images/W2/blogpic-16.png" alt="">
						</div>

						<div>
							<h4>Network</h4>
							<img width="100%" src="images/W2/ask-brain.jpeg" alt="">
						</div>

						<div>
							<h4>Two layer Neural Network</h4>
							<img width="100%" src="images/W2/artificial_neural_network_1-791x388.jpg" alt="">
						</div>
					</div>

				</section>
				<!-- ASSIGNMENT 1 A1-->
				<section>
					<header>
						<p><strong>Article 1:</strong></p>
					</header>
					<div class="content">
						<h3><strong>Throwing shapes</strong></h3>
						<!--<h4>Throwing shapes</h4>-->
						<p>The author examines that in order to discover how the brain works, we need to look to higher dimensions. The
							research states as our brains think, learn and remember, they create elaborate but ephemeral structures in
							mathematical dimensions. These structures which appear and disappear, could help us understand how the brain
							creates our thoughts and feelings. </p>

						<ul>
							<li>
								<p>What does this do for me?</p>
								<p>The research finding intrigued me where they have been using algebraic topology, a field of mathematics
									used to characterize higher- dimensional shapes, to explore the workings of the brain.</p>
							</li>
							<li>
								<p>What is interesting about this article? </p>
								<p>The blue brain project launched by the researchers aimed to simulate the entire human brain inside a
									computer. Not only have did they managed to do all their research in computer but they have also managed to
									replicate some if it’s finding through actually biological research.</p>
							</li>
							<li>
								<p>What questions is this making me ask?</p>
								<p>What are those higher dimension structures? What if the geometric structures they represent exist in
									mathematical dimensions higher than we can visualize?</p>
							</li>
						</ul>
					</div>
				</section>
				<!-- ASSIGNMENT 1 A2-->
				<section>
					<header>
						<p><strong></strong>Article 2:</strong></p>
					</header>
					<div class="content">
						<h3><strong>Why the Focus on Human Intelligence?</strong></h3>
						<br />
						<p>The article discusses the idea to reverse engineer the brain mechanisms that underlie human visual
							intelligence. </p>

						<ul>
							<li>
								<p>What does this do for me?</p>
								<p>The idea that a better understanding of the brain could lead to better computer algorithms and AI deepened
									my interest to learn more about the brain mechanism.</p>
							</li>
							<li>
								<p>What is interesting about this article? </p>
								<p>The Beautiful Brain, a 3-D interactive visualization based on the drawings of Santiago Ramón y Cajal
									interested me with the visual aspect of the human intelligence.</p>
							</li>
							<li>
								<p>What questions is this making me ask?</p>

							</li>
						</ul>
					</div>
				</section>
				<!-- ASSIGNMENT 1 A3-->
				<section>
					<header>
						<p><strong>Article 3: </strong></p>
					</header>
					<div class="content">
						<h3> <strong>Mapping’s Intelligent Agents</strong></h3>
						<br />
						<p>The article examines autonomous vehicles, sensing technologies, indigenous cartography, and non-human spatial
							sensibilities. </p>

						<ul>
							<li>
								<p>What does this do for me?</p>
								<p>The capacities and limitations of machine-mapping and autonomous spatial technologies needs attention.</p>
							</li>
							<li>
								<p>What is interesting about this article? </p>
								<p>Mapping made for and by machines is a big business opportunity at present. Yet mapping’s artificial
									intelligences also have the potential to transform myriad of design and research areas, to influence
									policy-making and governance, to support environmental preservation and public health.</p>
							</li>
							<li>
								<p>What questions is this making me ask?</p>
								<p>How machines conceptualize and operationalize space? How do they render our world measurable, navigable,
									usable, conservable?</p>
							</li>
						</ul>
					</div>
				</section>
				<!-- ASSIGNMENT 1 A4-->
				<section>
					<header>
						<p><strong>Article 4:</strong></p>
					</header>
					<div class="content">
						<h3><strong>Plumbing the Depths of Neural Nets</strong> </h3>
						<br />
						<p>Tomaso Poggio, the director of Center for Brains, Minds, and Machines (CBMM) at MIT’s McGovern Institute for
							Brain Research discuss the implications for human intelligence.</p>

						<ul>
							<li>
								<p>What does this do for me?</p>
								<p>The artificial neural networks, is modeled loosely after the human brain, They can train themselves to
									recognize complex patterns, and provide solutions to many problems in image recognition, speech recognition,
									and natural language processing.</p>
							</li>
							<li>
								<p>What is interesting about this article? </p>
								<p>The author explains that problem of intelligence is not only the engineering problem of building an
									intelligent machine, but the scientific problem of what intelligence is, how our brain works and how it
									creates the mind.</p>
							</li>
							<li>
								<p>What questions is this making me ask?</p>
								<p>What are the major technology trends driving Deep Learning? How to build, train and apply fully connected
									deep neural networks.</p>
							</li>
						</ul>
					</div>
				</section>
				<!-- ASSIGNMENT 1 A5-->
				<section>
					<header>
						<p><strong>Article 5:</strong></p>
					</header>
					<div class="content">
						<h3><strong>Interactive visualization of high-dimensional datasets</strong></h3>
						<br />
						<p>Embedding Projector, a system for interactive visualization and analysis of high-dimensional datasets used in
							machine learning projects. Researchers and developers often need to explore the properties of a specific
							embedding, and one way to analyze embedding is to visualize them.</p>

						<ul>
							<li>
								<p>What does this do for me?</p>
								<p>A new tool that could help users interpret machine learning models visually could help reduce common
									problems in machine leaning such as overfitting and underfitting that would eventually lead to better
									accuracy.</p>
							</li>
							<li>
								<p>What is interesting about this article? </p>
								<p>How the embedding projector helps reduce the arbitrary high-dimensional data into a simple two- or
									three-dimensional view is interesting.</p>
							</li>
							<li>
								<p>What questions is this making me ask?</p>
								<p>What are the major technology trends driving Deep Learning? How does it apply dimensionality reduction
									techniques such as t-SNE and PCA for an arbitrary dataset.</p>
							</li>
						</ul>
					</div>
				</section>
			</div>
		</div>
	</section>

	<!-- ASSIGNMENT 1-->
	<section class="wrapper style1 align-center">
		<div class="inner">
			<h2>Inspiration Cards</h2>
			<p>Areas of Interest</p>
			<div class="index align-left">
				<!-- Two -->
				<section>
					<header>
						<p><strong>Inspiration cards</strong></p>
					</header>
					<div class="content">
						<img width="85%" src="images/cards/Inspiration cards.jpg" alt="">
					</div>
				</section>
			</div>
		</div>
	</section>
	<!-- ASSIGNMENT 1-->
	<section class="wrapper style1 align-center">
		<div class="inner">
			<h2>Personal Interest Cards</h2>
			<div class="index align-left">
				<!-- Two -->
				<section>
					<header>
						<p><strong>Neural Networks</strong></p>
					</header>
					<div class="content">
						<img width="50%" src="images/cards/PIC-NN.JPG" alt="">
					</div>
				</section>

				<!-- Two -->
				<section>
					<header>
						<p><strong>Power of Algorithms</strong></p>
					</header>
					<div class="content">
						<img width="50%" src="images/cards/PIC-Algorithms.JPG" alt="">
					</div>
				</section>

				<!-- Two -->
				<section>
					<header>
						<p><strong>Prediction Machines</strong></p>
					</header>
					<div class="content">
						<img width="50%" src="images/cards/PIC-AI.JPG" alt="">
					</div>
				</section>

				<!-- Two -->
				<section>
					<header>
						<p><strong>Dark Matters</strong></p>
					</header>
					<div class="content">
						<img width="50%" src="images/cards/PIC-DarkMatter.JPG" alt="">
					</div>
				</section>

				<!-- Two -->
				<section>
					<header>
						<p><strong>API for Non-Profits</strong></p>
					</header>
					<div class="content">
						<img width="50%" src="images/cards/PIC-API.jpg" alt="">
					</div>
				</section>

			</div>
		</div>
	</section>
	<!-- ASSIGNMENT 1-->
	<section class="wrapper style1 align-center">
		<div class="inner">
			<h2>Questionniare</h2>
			<p>Initial Review Investigations</p>
			<div class="index align-left">
				<!-- Two -->
				<section>
					<header>
						<p><strong>How neural network works?</strong></p>
					</header>
					<div class="content">
						<ul>
							<li>How are neural networks formed?</li>
							<li>What are the types of neural network?</li>
							<li>How neurons firing in our brain create complex web of connections?</li>
							<!--li>How Human brain works?</li>-->
							<!--<li>Is Brain like a computer?</li>-->
							<li>What are artifical neural networks</li>
							<li>How does human mind conjures our sense of self?</li>

							<!--<li>can we model the Brain? </li>-->


						</ul>
					</div>
				</section>

				<!-- Two -->
				<section>
					<header>
						<h4><strong>What are some powerful <br />algorithms?</strong></h4>
					</header>
					<div class="content">
						<p>Algorithms are already all around us. It is what drives Google’s search engine, powers Netflix to figure out
							what we want to watch next, Amazon Alexa’s voice assistants, Tinder’s match-making, autonomous vehicles,
							high-speed trading and an ever-growing number of services and technologies. </p>


						<ul>
							<li>what is the ultimate algorithm with the potential to remake our world</li>

							<li>How to identify and highlight algorithmic bias?</li>
							<li>How to drive diversity and inclusiveness in today’s predictive decision-making tools?</li>
							<li>How can we bring more awareness about the negative impact of these automated systems?</li>
							</ol>
					</div>
				</section>

				<!-- Two -->
				<section>
					<header>
						<h4><strong>What does AI mean for <br />you and me?</strong></h4>
					</header>
					<div class="content">
						<p> Artificial Intelligence will affect everyone, everywhere. The past few years have seen rapid advances in AI,
							with new technologies achieving dramatic improvements in technical performance.</p>
						<p>Where does this ultimately lead? Software that thinks and does. Software with cognitive ability that predict
							people’s behavior and drive autonomous vehicles etc.</p>
						<ul>
							<li>Would prediction tools help improve productivity in our lives?</li>
							<li>Will it help reduce uncertainties in our day-to-day decision-making?</li>
							<li>Would Artificial Intelligence code a better world? A better future?</li>
							<li>Would it help to build a better, smarter and more connected world?</li>
							<li>What are the most important trend in the world of AI?</li>
							<li>Can design thinking open up new applications for AI?</li>
							<li>How might we ensure inclusion so that everyone can benefit from breakthroughs in AI?</li>
						</ul>
					</div>
				</section>

				<!-- Two -->
				<section>
					<header>
						<h4><strong>Is Dark Matter Real?</strong></h4>
					</header>
					<div class="content">
						<p></p>
						<ul>
							<li>Is dark matter real or just a hypothetical form?</li>
							<li>Why do physicists beleive dark matter do not interact with light particles</li>
							<li>Is mathematical proof sufficient to satisfy it's existence</li>
							<li>How long has dark matter been around?</li>
							<li>Is it related to Dark Energy?</li>
						</ul>
					</div>
				</section>

				<!-- Two -->
				<section>
					<header>
						<h4>How to create <strong>APIs for Non-Profit</strong></h4>
					</header>
					<div class="content">
						<p><strong><em>APIs are all about sharing</em></strong></strong>. It's an interface that lets one software
							program “talk” to another, exchanging
							data behind the scenes. APIs power much of what we do online. Startups and established companies alike are
							leveraging the technology to become a bigger part of our lives. </p>
						<ul>
							<li>How to to use API ecosystem to elevate non-profit works?</li>
							<li>How to harness the power of APIs for greater good or social causes?</li>
							<li>How can we use APIs to help non-profit organizations to wider their impact?</li>
							<li>How to leverage APIs from multiple open source platforms to build innovative social services?</li>
							<li>How to use APIs to collect charitable donations</li>
						</ul>
					</div>
				</section>
			</div>
		</div>
	</section>

	<!-- Footer -->
	<footer class="wrapper style1 align-center">
		<div class="inner">
			<ul class="icons">
				<li>
					<a href="#" class="icon style2 fa-twitter">
						<span class="label">Twitter</span>
					</a>
				</li>
				<li>
					<a href="#" class="icon style2 fa-facebook">
						<span class="label">Facebook</span>
					</a>
				</li>
				<li>
					<a href="#" class="icon style2 fa-instagram">
						<span class="label">Instagram</span>
					</a>
				</li>
				<li>
					<a href="#" class="icon style2 fa-linkedin">
						<span class="label">LinkedIn</span>
					</a>
				</li>
				<li>
					<a href="#" class="icon style2 fa-envelope">
						<span class="label">Email</span>
					</a>
				</li>
			</ul>
			<p>&copy; All Copyrights Reserved.</p>
		</div>
	</footer>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/skel.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>